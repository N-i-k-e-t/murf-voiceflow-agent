# ğŸ”Œ API Integration Guide with Visuals

## ğŸ“Š API Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        VoiceFlow APIs                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  ğŸ¯ Deepgram      â”‚  â”‚  ğŸ§  OpenAI       â”‚  â”‚  ğŸ”Š Murf Falcon  â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Speech-to-Text    â”‚  â”‚ Language Model   â”‚  â”‚ Text-to-Speech   â”‚  â”‚
â”‚  â”‚ (ASR)             â”‚  â”‚ (LLM)            â”‚  â”‚ (TTS)            â”‚  â”‚
â”‚  â”‚                   â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚
â”‚  â”‚ âœ… Real-time      â”‚  â”‚ âœ… Multi-turn    â”‚  â”‚ âœ… Streaming     â”‚  â”‚
â”‚  â”‚ âœ… Nova-3 Model   â”‚  â”‚ âœ… Context aware â”‚  â”‚ âœ… Natural voice â”‚  â”‚
â”‚  â”‚ âœ… Smart format   â”‚  â”‚ âœ… 20+ languages â”‚  â”‚ âœ… 40+ voices    â”‚  â”‚
â”‚  â”‚                   â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚
â”‚  â”‚ ğŸ”— REST API       â”‚  â”‚ ğŸ”— REST API      â”‚  â”‚ ğŸ”— REST API      â”‚  â”‚
â”‚  â”‚ ğŸ” Token auth     â”‚  â”‚ ğŸ” Key auth      â”‚  â”‚ ğŸ” Key auth      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. ğŸ¯ Deepgram API (Speech-to-Text)

### Endpoint Diagram

```
User Audio (WAV)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /v1/listen                     â”‚
â”‚  https://api.deepgram.com/v1/listen  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚  Headers:                            â”‚
â”‚  â”œâ”€ Authorization: Token {KEY}       â”‚
â”‚  â””â”€ Content-Type: audio/wav          â”‚
â”‚                                      â”‚
â”‚  Query Params:                       â”‚
â”‚  â”œâ”€ model=nova-3                     â”‚
â”‚  â”œâ”€ smart_format=true                â”‚
â”‚  â””â”€ language=en                      â”‚
â”‚                                      â”‚
â”‚  Body:                               â”‚
â”‚  â””â”€ [Binary WAV audio data]          â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response (200 OK)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                      â”‚
â”‚  {                                   â”‚
â”‚    "results": {                      â”‚
â”‚      "channels": [{                  â”‚
â”‚        "alternatives": [{            â”‚
â”‚          "transcript": "What is...",  â”‚
â”‚          "confidence": 0.95           â”‚
â”‚        }]                            â”‚
â”‚      }]                              â”‚
â”‚    }                                 â”‚
â”‚  }                                   â”‚
â”‚                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
Text Transcript
```

### Implementation in VoiceFlow

```python
# app/asr_deepgram.py

class DeepgramASRClient:
    def __init__(self):
        self.base_url = "https://api.deepgram.com/v1/listen"
        self.session = requests.Session()
        # Retry strategy with backoff
        
    def transcribe_wav(self, wav_bytes: bytes) -> Optional[str]:
        headers = {
            "Authorization": f"Token {DEEPGRAM_API_KEY}",
            "Content-Type": "audio/wav"
        }
        params = {
            "model": "nova-3",        # Latest accurate model
            "smart_format": "true",    # Enable punctuation
        }
        response = self.session.post(
            self.base_url,
            headers=headers,
            params=params,
            data=wav_bytes,
            timeout=REQUEST_TIMEOUT
        )
        # Extract transcript from response
        return response.json()["results"]["channels"][0]["alternatives"][0]["transcript"]
```

### Configuration

```dotenv
DEEPGRAM_API_KEY=your_deepgram_api_key_here
```

---

## 2. ğŸ§  OpenAI API (Language Model)

### Endpoint Diagram

```
Transcript Text + Context
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /v1/chat/completions               â”‚
â”‚  https://api.openai.com/v1/chat/completions
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  Headers:                                â”‚
â”‚  â”œâ”€ Authorization: Bearer {KEY}          â”‚
â”‚  â”œâ”€ Content-Type: application/json       â”‚
â”‚  â””â”€ User-Agent: voiceflow/1.0            â”‚
â”‚                                          â”‚
â”‚  Body (JSON):                            â”‚
â”‚  {                                       â”‚
â”‚    "model": "gpt-4o-mini",               â”‚
â”‚    "messages": [                         â”‚
â”‚      {                                   â”‚
â”‚        "role": "system",                 â”‚
â”‚        "content": "You are VoiceFlow..." â”‚
â”‚      },                                  â”‚
â”‚      {                                   â”‚
â”‚        "role": "user",                   â”‚
â”‚        "content": "What is AI?"          â”‚
â”‚      }                                   â”‚
â”‚    ],                                    â”‚
â”‚    "temperature": 0.7,                   â”‚
â”‚    "max_tokens": 500                     â”‚
â”‚  }                                       â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Response (200 OK)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  {                                       â”‚
â”‚    "id": "chatcmpl-xxx",                â”‚
â”‚    "object": "chat.completion",         â”‚
â”‚    "choices": [{                        â”‚
â”‚      "message": {                       â”‚
â”‚        "role": "assistant",             â”‚
â”‚        "content": "AI is a technology..."
â”‚      },                                 â”‚
â”‚      "finish_reason": "stop"            â”‚
â”‚    }],                                  â”‚
â”‚    "usage": {                           â”‚
â”‚      "prompt_tokens": 50,               â”‚
â”‚      "completion_tokens": 150,          â”‚
â”‚      "total_tokens": 200                â”‚
â”‚    }                                    â”‚
â”‚  }                                      â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
Response Text
```

### Implementation in VoiceFlow

```python
# app/llm_openai.py

from openai import OpenAI

class LLMClient:
    def __init__(self):
        self.client = OpenAI(api_key=OPENAI_API_KEY)
        
    def chat(self, messages: List[Dict[str, str]]) -> str:
        completion = self.client.chat.completions.create(
            model=OPENAI_MODEL,  # gpt-4o-mini
            messages=messages,    # [system, user, assistant, ...]
            temperature=0.7,      # Balanced creativity
            max_tokens=500        # Response length
        )
        return completion.choices[0].message.content.strip()
```

### Multi-Turn Conversation Example

```
Turn 1:
User:   "What is machine learning?"
Assistant: "Machine learning is..."

Turn 2:
User:   "Can you explain neural networks?"
Assistant: "Neural networks are inspired by..."
(Context from Turn 1 is maintained!)

Turn 3:
User:   "How does backpropagation work?"
Assistant: "Backpropagation is used to train..."
(Full context history is maintained!)
```

### Configuration

```dotenv
OPENAI_API_KEY=sk_your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini  # gpt-4o, gpt-4-turbo, etc.
```

---

## 3. ğŸ”Š Murf Falcon API (Text-to-Speech)

### Endpoint Diagram

```
Response Text
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  POST /v1/speech/synthesize              â”‚
â”‚  (via Murf Python SDK)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  Parameters:                             â”‚
â”‚  â”œâ”€ text: "Your response text"          â”‚
â”‚  â”œâ”€ voice_id: "Matthew"                 â”‚
â”‚  â”œâ”€ model: "FALCON"                     â”‚
â”‚  â”œâ”€ sample_rate: 24000                  â”‚
â”‚  â”œâ”€ format: "PCM"                       â”‚
â”‚  â””â”€ region: "GLOBAL"                    â”‚
â”‚                                          â”‚
â”‚  Returns:                                â”‚
â”‚  â””â”€ Iterator of audio chunks (Streaming)
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Audio Stream (Real-time)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                          â”‚
â”‚  Chunk 1: [PCM data - 4KB]              â”‚
â”‚  Chunk 2: [PCM data - 4KB]              â”‚
â”‚  Chunk 3: [PCM data - 4KB]              â”‚
â”‚  ...                                     â”‚
â”‚  Chunk N: [PCM data - remaining]        â”‚
â”‚                                          â”‚
â”‚  Total: 24kHz, mono, 16-bit PCM         â”‚
â”‚                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
Audio Playback (Live Streaming!)
```

### Implementation in VoiceFlow

```python
# app/tts_murf.py

from murf import Murf, MurfRegion

class MurfTTSClient:
    def __init__(self):
        region = getattr(MurfRegion, MURF_REGION, MurfRegion.GLOBAL)
        self.client = Murf(api_key=MURF_API_KEY, region=region)
        
    def stream_tts(self, text: str) -> Iterable[bytes]:
        # Real-time streaming
        audio_stream = self.client.text_to_speech.stream(
            text=text,
            voice_id=MURF_VOICE_ID,        # "Matthew"
            model="FALCON",                 # Latest model
            sample_rate=24000,              # Hz
            format="PCM",                   # 16-bit PCM
            multi_native_locale="en-US"    # English
        )
        return audio_stream  # Iterator of bytes chunks
```

### Available Voices

```
Murf Falcon Voices:
â”œâ”€ Matthew (Male, Professional)
â”œâ”€ Evan (Male, Friendly)
â”œâ”€ Sarah (Female, Clear)
â”œâ”€ Emma (Female, Warm)
â”œâ”€ James (Male, Deep)
â”œâ”€ Lisa (Female, Energetic)
â””â”€ ... (40+ voices available)
```

### Configuration

```dotenv
MURF_API_KEY=your_murf_api_key_here
MURF_REGION=GLOBAL          # GLOBAL, IN, US
MURF_VOICE_ID=Matthew       # Any Murf voice
```

---

## ğŸ”„ Complete API Flow with Timing

```
Time: 00:00 â”¬â”€ User presses Enter
            â”‚
Time: 00:01 â”‚ Recording starts (audio input)
            â”‚
Time: 00:10 â”‚ Recording ends
            â”‚
            â”œâ”€ WAV data ready (10 seconds of audio â‰ˆ 320KB)
            â”‚
Time: 00:11 â”‚ Deepgram ASR Request
            â”‚ â”œâ”€ Network latency: ~200ms
            â”‚ â”œâ”€ API processing: ~1-2s
            â”‚ â””â”€ Network latency: ~200ms
            â”‚
Time: 00:13 â”‚ Transcript received: "What is machine learning?"
            â”‚
Time: 00:14 â”‚ OpenAI LLM Request
            â”‚ â”œâ”€ Network latency: ~100ms
            â”‚ â”œâ”€ API processing: ~1-2s
            â”‚ â””â”€ Network latency: ~100ms
            â”‚
Time: 00:16 â”‚ Response received: "Machine learning is a subset of AI..."
            â”‚
Time: 00:17 â”‚ Murf Falcon TTS Request (Streaming)
            â”‚ â”œâ”€ Network latency: ~100ms
            â”‚ â””â”€ Streaming audio chunks (~2s)
            â”‚
Time: 00:19 â”‚ Audio playback starts (streaming in real-time)
            â”‚
Time: 00:22 â”‚ Audio playback ends
            â”‚
            â””â”€ Total latency: 22 seconds (~2-3s API latency + 10s recording + 10s playback)
```

---

## ğŸ›¡ï¸ Error Handling for APIs

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Call                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Success?      â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚      â”‚
       Yes â”‚   Noâ”‚
         â”‚      â”‚
         â”‚      â–¼
         â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚   â”‚  HTTP Status Code   â”‚
         â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
         â”‚        â”‚    â”‚    â”‚
         â”‚      400 429  500  ???
         â”‚        â”‚    â”‚    â”‚
         â”‚        â–¼    â–¼    â–¼
         â”‚     Invalid Too  Server
         â”‚     Request Rate Error
         â”‚        â”‚    â”‚    â”‚
         â”‚        â”‚    â–¼    â–¼
         â”‚        â”‚  Retry  Retry
         â”‚        â”‚  (Backoff)
         â”‚        â”‚    â”‚    â”‚
         â”‚        â–¼    â–¼    â–¼
         â”‚     Log & Notify User
         â”‚        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Continue/Fail
```

---

## ğŸ“ API Key Setup Steps

### 1. Deepgram

```
1. Go to https://console.deepgram.com
2. Sign up / Login
3. Create new API key
4. Copy the key
5. Add to .env:
   DEEPGRAM_API_KEY=<paste-key-here>
```

### 2. OpenAI

```
1. Go to https://platform.openai.com/api-keys
2. Sign up / Login
3. Create new secret key
4. Copy the key (only shown once!)
5. Add to .env:
   OPENAI_API_KEY=<paste-key-here>
```

### 3. Murf Falcon

```
1. Go to https://murf.ai/dashboard
2. Sign up / Login
3. Create new API key
4. Copy the key
5. Add to .env:
   MURF_API_KEY=<paste-key-here>
```

---

## ğŸ” API Response Times (Benchmarks)

| Operation | Time | Range |
|-----------|------|-------|
| Deepgram ASR | 1-2s | Depends on audio length |
| OpenAI LLM | 1-2s | Depends on response length |
| Murf TTS | 1-2s | Depends on text length |
| Network (total) | ~400ms | Per API call |
| **Total Pipeline** | **2-3s** | User to Response |

---

## ğŸš€ Rate Limits

| API | Free Tier | Paid Tier |
|-----|-----------|-----------|
| **Deepgram** | 50,000 min/mo | Pay per usage |
| **OpenAI** | $5 credit | $20+/mo |
| **Murf Falcon** | Limited | Pay per usage |

---

This guide provides complete visual reference for all API integrations!
